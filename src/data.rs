//! Load and store data in the form of JSON files in a folder hierarchy.
//!
//! User-generated:
//!
//! - `ignore`: gitignore-like, used for stats, not during gathering
//! - `authors.toml`: rename and consolidate authors
//!
//! Generated by blamegraph:
//!
//! - `log.json`: list of commits to use for stats, in reverse chronological order
//! - `commits/<hash>.json`: metadata for a specific commit
//! - `blames/<hash>.json`: blame data for a specific commit

mod authors;
mod blame;
mod commit;

use std::{
    collections::{hash_map::Entry, HashMap, HashSet},
    fs,
    io::ErrorKind,
    os::unix::ffi::OsStrExt,
    path::{Path, PathBuf},
};

use anyhow::Context;
use serde::{de::DeserializeOwned, Serialize};
use tempfile::NamedTempFile;

pub use self::{authors::Authors, blame::Blame, commit::Commit};

pub struct Data {
    dir: PathBuf,
    commit_cache: HashMap<String, Commit>,
}

impl Data {
    pub fn new(dir: PathBuf) -> Self {
        Self {
            dir,
            commit_cache: HashMap::new(),
        }
    }

    fn load_json<T: DeserializeOwned>(path: &Path) -> anyhow::Result<T> {
        Ok(serde_json::from_str(&fs::read_to_string(path)?)?)
    }

    fn save_json<T: Serialize>(path: &Path, value: &T) -> anyhow::Result<()> {
        let parent = path.parent().unwrap();
        fs::create_dir_all(parent)?;
        let tmp_file = NamedTempFile::new_in(parent)?;
        serde_json::to_writer(&tmp_file, value)?;
        tmp_file.persist(path)?;
        Ok(())
    }

    pub fn load_ignore() -> anyhow::Result<()> {
        todo!()
    }

    pub fn load_authors(&self) -> anyhow::Result<Authors> {
        let path = self.dir.join("authors.toml");
        let authors = match fs::read_to_string(&path) {
            Ok(s) => toml::from_str::<Authors>(&s)?,
            Err(e) if e.kind() == ErrorKind::NotFound => Authors::default(),
            Err(e) => Err(e).context(format!("failed to load authors from {}", path.display()))?,
        };
        authors.check_for_cycles()?;
        Ok(authors)
    }

    pub fn load_log(&self) -> anyhow::Result<Vec<Commit>> {
        let path = self.dir.join("log.json");
        let log = match fs::read_to_string(&path) {
            Ok(s) => serde_json::from_str::<Vec<Commit>>(&s)?,
            Err(e) if e.kind() == ErrorKind::NotFound => vec![],
            Err(e) => Err(e).context(format!("failed to load log from {}", path.display()))?,
        };
        Ok(log)
    }

    pub fn save_log(&self, log: &Vec<Commit>) -> anyhow::Result<()> {
        let path = self.dir.join("log.json");
        Self::save_json(&path, log).context(format!("failed to save log to {}", path.display()))
    }

    pub fn load_commit(&mut self, hash: String) -> anyhow::Result<Commit> {
        match self.commit_cache.entry(hash) {
            Entry::Occupied(entry) => Ok(entry.get().clone()),
            Entry::Vacant(entry) => {
                let path = self
                    .dir
                    .join("commits")
                    .join(entry.key())
                    .with_extension("json");

                let commit = Self::load_json::<Commit>(&path)
                    .context(format!("failed to load commit from {}", path.display()))?;

                entry.insert(commit.clone());
                Ok(commit)
            }
        }
    }

    pub fn save_commit(&self, hash: &str, commit: &Commit) -> anyhow::Result<()> {
        let path = self.dir.join("commits").join(hash).with_extension("json");

        if path.exists() {
            // No need to overwrite a perfectly good file. The commit info won't
            // have changed since the last time we looked at it. After all, it
            // has the same hash.
            return Ok(());
        }

        Self::save_json(&path, commit)
            .context(format!("failed to save commit to {}", path.display()))
    }

    pub fn load_known_blames(&self) -> anyhow::Result<HashSet<String>> {
        // It doesn't matter if this includes temporary files or other weird
        // files. It's only used to prevent recalculating a blame that was
        // already calculated.
        let mut result = HashSet::new();

        let path = self.dir.join("blames");
        let entries = match fs::read_dir(&path) {
            Ok(e) => e,
            Err(e) if e.kind() == ErrorKind::NotFound => return Ok(result),
            Err(e) => Err(e).context(format!("failed to search blames in {}", path.display()))?,
        };

        for entry in entries {
            let entry = entry.context(format!("failed to search blames in {}", path.display()))?;

            let file_type = entry
                .file_type()
                .context(format!("failed to inspect {}", entry.path().display()))?;

            if file_type.is_file() {
                let path = entry.path();
                let name = path.file_stem().unwrap();
                let name = String::from_utf8_lossy(name.as_bytes()).to_string();
                result.insert(name);
            }
        }

        Ok(result)
    }

    pub fn load_blame(&self, hash: &str) -> anyhow::Result<Blame> {
        let path = self.dir.join("blames").join(hash).with_extension("json");
        Self::load_json(&path).context(format!("failed to load blame from {}", path.display()))
    }

    pub fn save_blame(&self, hash: &str, blame: &Blame) -> anyhow::Result<()> {
        let path = self.dir.join("blames").join(hash).with_extension("json");
        Self::save_json(&path, blame).context(format!("failed to save blame to {}", path.display()))
    }
}
